{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is inspired by the code from the Week 8 Discussion\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + \"train\" + \"/\" + city + \"_inputs\"\n",
    "    f_out = ROOT_PATH + \"train\" + \"/\" + city + \"_outputs\"\n",
    "    \n",
    "    inputs = None\n",
    "    outputs = None\n",
    "    \n",
    "    if city==\"all\":\n",
    "        allInputs = np.zeros((0,50,2))\n",
    "        allOutputs = np.zeros((0,60,2))\n",
    "        for city in cities:\n",
    "            if split==\"train\":\n",
    "                f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "                inputs = pickle.load(open(f_in, \"rb\"))\n",
    "                n = len(inputs)\n",
    "                allInputs = np.concatenate((allInputs, np.asarray(inputs)[:int(n * 0.8)]))\n",
    "\n",
    "                f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "                outputs = pickle.load(open(f_out, \"rb\"))\n",
    "                allOutputs = np.concatenate((allOutputs, np.asarray(outputs)[:int(n * 0.8)]))\n",
    "\n",
    "            elif split == 'val':\n",
    "                f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "                inputs = pickle.load(open(f_in, \"rb\"))\n",
    "                n = len(inputs)\n",
    "                allInputs = np.concatenate((allInputs, np.asarray(inputs)[int(n * 0.8):]))\n",
    "\n",
    "                f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "                outputs = pickle.load(open(f_out, \"rb\"))\n",
    "                allOutputs = np.concatenate((allOutputs, np.asarray(outputs)[int(n * 0.8):]))\n",
    "\n",
    "            else:\n",
    "                f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "                inputs = pickle.load(open(f_in, \"rb\"))\n",
    "                n = len(inputs)\n",
    "                allInputs = np.concatenate((allInputs, np.asarray(inputs)))\n",
    "                \n",
    "\n",
    "        return allInputs, allOutputs\n",
    "    \n",
    "    if split==\"train\":\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "        \n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "    \n",
    "    elif split==\"val\":\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "        \n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.8):]\n",
    "    \n",
    "    else:\n",
    "        f_in = ROOT_PATH + spiit + \"/\" + city + \"_inputs\"\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "        return inputs\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'all' \n",
    "train_dataset  = ArgoverseDataset(city = city, split = \"train\")\n",
    "val_dataset = ArgoverseDataset(city = city, split = \"val\")\n",
    "test_dataset = get_city_trajectories(city = city, split = \"test\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 20  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "04f672e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is inspired by the code from the Week 8 Discussion\n",
    "from torch import nn, optim\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 100).float()\n",
    "        x = self.model(x)\n",
    "        x = x.reshape(-1, 60, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "ac3de7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "5b77ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "opt = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d015a",
   "metadata": {},
   "source": [
    "## Train and Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "2cd4c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.267403841018677\n",
      "epoch 0  RMSE: 1149.4500727406355 MSE: 1321235.469723452\n",
      "epoch 1  RMSE: 670.9788606835506 MSE: 450212.6314841956\n",
      "epoch 2  RMSE: 540.687425391712 MSE: 292342.8919767182\n",
      "epoch 3  RMSE: 537.5190483064304 MSE: 288926.72729225067\n",
      "epoch 4  RMSE: 524.4653857042928 MSE: 275063.94080195256\n",
      "epoch 5  RMSE: 488.0815245564514 MSE: 238223.57461334992\n",
      "epoch 6  RMSE: 467.0367504930891 MSE: 218123.32631114393\n",
      "epoch 7  RMSE: 470.70547101855874 MSE: 221563.64044680324\n",
      "epoch 8  RMSE: 492.1183880911387 MSE: 242180.5078974206\n",
      "epoch 9  RMSE: 410.55998944570314 MSE: 168559.50493365587\n",
      "epoch 10  RMSE: 435.7964867931452 MSE: 189918.577901248\n",
      "epoch 11  RMSE: 367.72640601534124 MSE: 135222.70968095958\n",
      "epoch 12  RMSE: 390.52495119176325 MSE: 152509.73750332906\n",
      "epoch 13  RMSE: 384.51220235216886 MSE: 147849.63375771526\n",
      "epoch 14  RMSE: 352.53952662561676 MSE: 124284.11783341395\n",
      "epoch 15  RMSE: 381.3267102833245 MSE: 145410.0599755025\n",
      "epoch 16  RMSE: 347.8666545979237 MSE: 121011.20938115114\n",
      "epoch 17  RMSE: 323.7609682038642 MSE: 104821.16453230355\n",
      "epoch 18  RMSE: 342.89794589324225 MSE: 117579.00129780488\n",
      "epoch 19  RMSE: 320.39557942869993 MSE: 102653.32731745235\n",
      "epoch 20  RMSE: 283.1623192896033 MSE: 80180.89906546727\n",
      "epoch 21  RMSE: 310.65274085721103 MSE: 96505.12540209752\n",
      "epoch 22  RMSE: 303.31547783707083 MSE: 92000.27909553061\n",
      "epoch 23  RMSE: 281.68995214026467 MSE: 79349.22913678459\n",
      "epoch 24  RMSE: 295.5873177251744 MSE: 87371.86239996318\n",
      "epoch 25  RMSE: 286.8791396647775 MSE: 82299.64077480292\n",
      "epoch 26  RMSE: 264.67076741196047 MSE: 70050.61512243608\n",
      "epoch 27  RMSE: 257.43853898861227 MSE: 66274.60135659124\n",
      "epoch 28  RMSE: 269.44169415255766 MSE: 72598.82654780043\n",
      "epoch 29  RMSE: 283.82277171050544 MSE: 80555.36574143369\n",
      "epoch 30  RMSE: 269.92991571589084 MSE: 72862.15939838794\n",
      "epoch 31  RMSE: 266.73366398980994 MSE: 71146.84750542884\n",
      "epoch 32  RMSE: 293.3130492662869 MSE: 86032.54486988724\n",
      "epoch 33  RMSE: 255.6711779522937 MSE: 65367.75123551344\n",
      "epoch 34  RMSE: 254.56049533926998 MSE: 64801.045787374496\n",
      "epoch 35  RMSE: 247.36609955595767 MSE: 61189.987209527964\n",
      "epoch 36  RMSE: 239.7650881431446 MSE: 57487.297492289894\n",
      "epoch 37  RMSE: 235.78147383060025 MSE: 55592.90340173003\n",
      "epoch 38  RMSE: 246.1645016815509 MSE: 60596.96188812627\n",
      "epoch 39  RMSE: 233.4681200746161 MSE: 54507.363091175364\n",
      "epoch 40  RMSE: 234.2462482046757 MSE: 54871.304797966535\n",
      "epoch 41  RMSE: 242.23547969827274 MSE: 58678.0276246523\n",
      "epoch 42  RMSE: 273.5459518406941 MSE: 74827.38776843135\n",
      "epoch 43  RMSE: 240.83323447292204 MSE: 58000.646826689444\n",
      "epoch 44  RMSE: 267.4807873306306 MSE: 71545.97159101404\n",
      "epoch 45  RMSE: 241.93546570328635 MSE: 58532.769565066046\n",
      "epoch 46  RMSE: 232.00044502818386 MSE: 53824.206493275364\n",
      "epoch 47  RMSE: 235.9188385943003 MSE: 55657.69840368351\n",
      "epoch 48  RMSE: 248.35022015805208 MSE: 61677.83185255293\n",
      "epoch 49  RMSE: 226.27698629395584 MSE: 51201.274526275076\n"
     ]
    }
   ],
   "source": [
    "#This code is inspired by the code from the Week 8 Discussion\n",
    "import time\n",
    "import math\n",
    "\n",
    "indexArray = []\n",
    "lossArray = []\n",
    "for epoch in range(num_epochs):\n",
    "    if (epoch == 0):\n",
    "        startTime = time.time()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, out = sample_batch\n",
    "        preds = model(inp)\n",
    "        loss = ((preds - out) ** 2).sum()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    if (epoch == 0):\n",
    "        endTime = time.time()\n",
    "        print(endTime - startTime)\n",
    "    \n",
    "    indexArray.append(epoch)\n",
    "    lossArray.append( math.sqrt(total_loss / len(train_dataset )) )\n",
    "    \n",
    "    print('epoch {}  RMSE: {} MSE: {}'.format(epoch, math.sqrt(total_loss / len(train_dataset)), total_loss / len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "34bd8a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 202.00940829359465\n"
     ]
    }
   ],
   "source": [
    "#This code is inspired by the code from the Week 8 Discussion\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz)\n",
    "\n",
    "val_loss = 0\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out = sample_batch\n",
    "    preds = model(inp)\n",
    "    loss = ((preds - out) ** 2).sum()\n",
    "\n",
    "    val_loss += loss.item()\n",
    "print('loss: {}'.format(math.sqrt(val_loss / len(val_dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86692b9a",
   "metadata": {},
   "source": [
    "## Test Algorithm and Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "538afa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.zeros((test_dataset.shape[0], 120))\n",
    "for inputIndex in range(0, test_dataset.shape[0]):\n",
    "        output = model(torch.tensor(test_dataset[inputIndex]))\n",
    "        output = output.reshape(-1,120)\n",
    "        for outputIndex in range (0, 120):\n",
    "            outputs[inputIndex][outputIndex] = output[0][outputIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "236a8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = []\n",
    "for index in range(0, 120):\n",
    "    columns.append(\"v\" + str(index))\n",
    "citynames = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "testDataAmounts = [6325, 7971, 6361, 3671, 3829, 1686]\n",
    "rows = []\n",
    "for arrayIndex in range(0, 6):\n",
    "    for itemIndex in range(0, testDataAmounts[arrayIndex]):\n",
    "        rows.append(str(itemIndex) + \"_\" + citynames[arrayIndex])\n",
    "\n",
    "df = pd.DataFrame(outputs, index=rows, columns=columns)\n",
    "df.to_csv('submission.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
