{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "718c38cf",
   "metadata": {},
   "source": [
    "## Install the package dependencies before running this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16ac7530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    number of trajectories in each city\\n    # austin --  train: 43041 test: 6325 \\n    # miami -- train: 55029 test:7971\\n    # pittsburgh -- train: 43544 test: 6361\\n    # dearborn -- train: 24465 test: 3671\\n    # washington-dc -- train: 25744 test: 3829\\n    # palo-alto -- train:  11993 test:1686\\n\\n    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\\n    \\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os, os.path \n",
    "import numpy \n",
    "import pickle\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\"\"\"\n",
    "    number of trajectories in each city\n",
    "    # austin --  train: 43041 test: 6325 \n",
    "    # miami -- train: 55029 test:7971\n",
    "    # pittsburgh -- train: 43544 test: 6361\n",
    "    # dearborn -- train: 24465 test: 3671\n",
    "    # washington-dc -- train: 25744 test: 3829\n",
    "    # palo-alto -- train:  11993 test:1686\n",
    "\n",
    "    trajectories sampled at 10HZ rate, input 5 seconds, output 6 seconds\n",
    "    \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b472cf2",
   "metadata": {},
   "source": [
    "## Create training, validation, and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "091abbb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#This code is inspired by the code from the Week 7 Discussion\n",
    "from glob import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = \"./\"\n",
    "\n",
    "cities = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "splits = [\"train\", \"test\"]\n",
    "\n",
    "def get_city_trajectories(city=\"palo-alto\", split=\"train\", normalized=False):\n",
    "    f_in = ROOT_PATH + \"train\" + \"/\" + city + \"_inputs\"\n",
    "    f_out = ROOT_PATH + \"train\" + \"/\" + city + \"_outputs\"\n",
    "    \n",
    "    inputs = None\n",
    "    outputs = None\n",
    "    \n",
    "    if city==\"all\":\n",
    "        allInputs = np.zeros((0,50,2))\n",
    "        allOutputs = np.zeros((0,60,2))\n",
    "        for city in cities:\n",
    "            if split==\"train\":\n",
    "                f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "                inputs = pickle.load(open(f_in, \"rb\"))\n",
    "                n = len(inputs)\n",
    "                allInputs = np.concatenate((allInputs, np.asarray(inputs)[:int(n * 0.8)]))\n",
    "\n",
    "                f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "                outputs = pickle.load(open(f_out, \"rb\"))\n",
    "                allOutputs = np.concatenate((allOutputs, np.asarray(outputs)[:int(n * 0.8)]))\n",
    "\n",
    "            elif split == 'val':\n",
    "                f_in = ROOT_PATH + 'train' + \"/\" + city + \"_inputs\"\n",
    "                inputs = pickle.load(open(f_in, \"rb\"))\n",
    "                n = len(inputs)\n",
    "                allInputs = np.concatenate((allInputs, np.asarray(inputs)[int(n * 0.8):]))\n",
    "\n",
    "                f_out = ROOT_PATH + 'train' + \"/\" + city + \"_outputs\"\n",
    "                outputs = pickle.load(open(f_out, \"rb\"))\n",
    "                allOutputs = np.concatenate((allOutputs, np.asarray(outputs)[int(n * 0.8):]))\n",
    "\n",
    "            else:\n",
    "                f_in = ROOT_PATH + split + \"/\" + city + \"_inputs\"\n",
    "                inputs = pickle.load(open(f_in, \"rb\"))\n",
    "                n = len(inputs)\n",
    "                allInputs = np.concatenate((allInputs, np.asarray(inputs)))\n",
    "                \n",
    "\n",
    "        return allInputs, allOutputs\n",
    "    \n",
    "    if split==\"train\":\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[:int(n * 0.8)]\n",
    "        \n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[:int(n * 0.8)]\n",
    "    \n",
    "    elif split==\"val\":\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)[int(n * 0.8):]\n",
    "        \n",
    "        outputs = pickle.load(open(f_out, \"rb\"))\n",
    "        outputs = np.asarray(outputs)[int(n * 0.8):]\n",
    "    \n",
    "    else:\n",
    "        f_in = ROOT_PATH + spiit + \"/\" + city + \"_inputs\"\n",
    "        f_out = ROOT_PATH + split + \"/\" + city + \"_outputs\"\n",
    "        inputs = pickle.load(open(f_in, \"rb\"))\n",
    "        n = len(inputs)\n",
    "        inputs = np.asarray(inputs)\n",
    "        return inputs\n",
    "\n",
    "    return inputs, outputs\n",
    "\n",
    "class ArgoverseDataset(Dataset):\n",
    "    \"\"\"Dataset class for Argoverse\"\"\"\n",
    "    def __init__(self, city: str, split:str, transform=None):\n",
    "        super(ArgoverseDataset, self).__init__()\n",
    "        self.transform = transform\n",
    "\n",
    "        self.inputs, self.outputs = get_city_trajectories(city=city, split=split, normalized=False)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        data = (self.inputs[idx], self.outputs[idx])\n",
    "            \n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "\n",
    "        return data\n",
    "\n",
    "# intialize a dataset\n",
    "city = 'all' \n",
    "train_dataset  = ArgoverseDataset(city = city, split = \"train\")\n",
    "val_dataset = ArgoverseDataset(city = city, split = \"val\")\n",
    "test_dataset = get_city_trajectories(city = city, split = \"test\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058453cc",
   "metadata": {},
   "source": [
    "## Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c14f0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sz = 20  # batch size \n",
    "train_loader = DataLoader(train_dataset,batch_size=batch_sz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04f672e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code is inspired by the code from the Week 7 Discussion\n",
    "from torch import nn, optim\n",
    "\n",
    "class Model(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(100, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 120),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(120, 120)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.reshape(-1, 100).float()\n",
    "        x = self.model(x)\n",
    "        x = x.reshape(-1, 60, 2)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ac3de7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "weight_decay = 0.00001\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b77ca5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model()\n",
    "opt = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819d015a",
   "metadata": {},
   "source": [
    "## Train and Validate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2cd4c8e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.326593160629272\n",
      "epoch 0  RMSE: 1218.974146683382 MSE: 1485897.9702824794\n",
      "epoch 1  RMSE: 742.7175980160783 MSE: 551629.430402773\n",
      "epoch 2  RMSE: 687.5370499835594 MSE: 472707.1951000955\n",
      "epoch 3  RMSE: 651.1385277589699 MSE: 423981.38233211875\n",
      "epoch 4  RMSE: 632.7900863104652 MSE: 400423.29333280603\n",
      "epoch 5  RMSE: 562.4873208565477 MSE: 316391.98612437694\n",
      "epoch 6  RMSE: 559.8499143623342 MSE: 313431.9266115129\n",
      "epoch 7  RMSE: 565.7494217395271 MSE: 320072.40819860925\n",
      "epoch 8  RMSE: 495.8951480349337 MSE: 245911.99784458883\n",
      "epoch 9  RMSE: 534.9669064374582 MSE: 286189.5909832642\n",
      "epoch 10  RMSE: 518.2426430860526 MSE: 268575.43711281766\n",
      "epoch 11  RMSE: 523.7283365771924 MSE: 274291.37053391297\n",
      "epoch 12  RMSE: 434.3020149986178 MSE: 188618.24023185964\n",
      "epoch 13  RMSE: 425.6830729540998 MSE: 181206.07859964547\n",
      "epoch 14  RMSE: 421.9940716431123 MSE: 178078.9965019322\n",
      "epoch 15  RMSE: 414.40526758823046 MSE: 171731.7258048729\n",
      "epoch 16  RMSE: 376.1689037156572 MSE: 141503.0441226394\n",
      "epoch 17  RMSE: 390.0389736877831 MSE: 152130.40099541913\n",
      "epoch 18  RMSE: 406.22941151238894 MSE: 165022.33477770185\n",
      "epoch 19  RMSE: 375.46726593779397 MSE: 140975.66779080208\n",
      "epoch 20  RMSE: 355.74705321640823 MSE: 126555.965872158\n",
      "epoch 21  RMSE: 356.37785431216736 MSE: 127005.17504414439\n",
      "epoch 22  RMSE: 353.1300944719183 MSE: 124700.86362174597\n",
      "epoch 23  RMSE: 377.9610449084185 MSE: 142854.55146826355\n",
      "epoch 24  RMSE: 344.575821251276 MSE: 118732.49659099133\n",
      "epoch 25  RMSE: 397.525753746319 MSE: 158026.72489157907\n",
      "epoch 26  RMSE: 379.01293323306925 MSE: 143650.80355793503\n",
      "epoch 27  RMSE: 351.7169451926224 MSE: 123704.80953563015\n",
      "epoch 28  RMSE: 340.6855225511802 MSE: 116066.62527597073\n",
      "epoch 29  RMSE: 327.10424152865613 MSE: 106997.18482603742\n",
      "epoch 30  RMSE: 350.81704640403524 MSE: 123072.600047651\n",
      "epoch 31  RMSE: 339.77023494042004 MSE: 115443.81255146825\n",
      "epoch 32  RMSE: 334.3758183620017 MSE: 111807.18790525838\n",
      "epoch 33  RMSE: 310.11545928356975 MSE: 96171.59808665939\n",
      "epoch 34  RMSE: 306.5944597441459 MSE: 94000.16274580472\n",
      "epoch 35  RMSE: 305.2736798646259 MSE: 93192.01961809008\n",
      "epoch 36  RMSE: 338.36550395565365 MSE: 114491.21426716348\n",
      "epoch 37  RMSE: 338.1548261391539 MSE: 114348.68644120141\n",
      "epoch 38  RMSE: 319.13779618328056 MSE: 101848.93295272111\n",
      "epoch 39  RMSE: 305.08358247016156 MSE: 93075.99229282785\n",
      "epoch 40  RMSE: 340.5398261214412 MSE: 115967.37317482139\n",
      "epoch 41  RMSE: 287.7425742523437 MSE: 82795.78903736552\n",
      "epoch 42  RMSE: 313.9529747855943 MSE: 98566.47037672398\n",
      "epoch 43  RMSE: 351.9896579130287 MSE: 123896.71927773094\n",
      "epoch 44  RMSE: 286.9473729726622 MSE: 82338.79485591213\n",
      "epoch 45  RMSE: 294.2007650112169 MSE: 86554.09013318525\n",
      "epoch 46  RMSE: 287.91088465284173 MSE: 82892.67750158193\n",
      "epoch 47  RMSE: 304.7956544748663 MSE: 92900.39098676207\n",
      "epoch 48  RMSE: 281.0471742945518 MSE: 78987.51417895217\n",
      "epoch 49  RMSE: 275.4542763389373 MSE: 75875.05835340764\n"
     ]
    }
   ],
   "source": [
    "#This code is inspired by the code from the Week 7 Discussion\n",
    "import time\n",
    "import math\n",
    "for epoch in range(num_epochs):\n",
    "    if (epoch == 0):\n",
    "        startTime = time.time()\n",
    "    \n",
    "    total_loss = 0\n",
    "    for i_batch, sample_batch in enumerate(train_loader):\n",
    "        inp, out = sample_batch\n",
    "        preds = model(inp)\n",
    "        loss = ((preds - out) ** 2).sum()\n",
    "        \n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    if (epoch == 0):\n",
    "        endTime = time.time()\n",
    "        print(endTime - startTime)\n",
    "    \n",
    "    print('epoch {}  RMSE: {} MSE: {}'.format(epoch, math.sqrt(total_loss / len(train_dataset)), total_loss / len(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34bd8a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 188.59134410253728\n"
     ]
    }
   ],
   "source": [
    "#This code is inspired by the code from the Week 7 Discussion\n",
    "val_loader = DataLoader(val_dataset,batch_size=batch_sz)\n",
    "\n",
    "val_loss = 0\n",
    "for i_batch, sample_batch in enumerate(val_loader):\n",
    "    inp, out = sample_batch\n",
    "    preds = model(inp)\n",
    "    loss = ((preds - out) ** 2).sum()\n",
    "\n",
    "    val_loss += loss.item()\n",
    "print('loss: {}'.format(math.sqrt(val_loss / len(val_dataset))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86692b9a",
   "metadata": {},
   "source": [
    "## Test Algorithm and Convert to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "538afa77",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = np.zeros((test_dataset.shape[0], 120))\n",
    "for inputIndex in range(0, test_dataset.shape[0]):\n",
    "        output = model(torch.tensor(test_dataset[inputIndex]))\n",
    "        output = output.reshape(-1,120)\n",
    "        for outputIndex in range (0, 120):\n",
    "            outputs[inputIndex][outputIndex] = output[0][outputIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "236a8e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "columns = []\n",
    "for index in range(0, 120):\n",
    "    columns.append(\"v\" + str(index))\n",
    "citynames = [\"austin\", \"miami\", \"pittsburgh\", \"dearborn\", \"washington-dc\", \"palo-alto\"]\n",
    "testDataAmounts = [6325, 7971, 6361, 3671, 3829, 1686]\n",
    "rows = []\n",
    "for arrayIndex in range(0, 6):\n",
    "    for itemIndex in range(0, testDataAmounts[arrayIndex]):\n",
    "        rows.append(str(itemIndex) + \"_\" + citynames[arrayIndex])\n",
    "\n",
    "df = pd.DataFrame(outputs, index=rows, columns=columns)\n",
    "df.to_csv('submission.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb4aca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
